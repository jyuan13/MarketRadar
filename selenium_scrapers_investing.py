# selenium_scrapers_investing.py
# -----------------------------------------------------------------------------
# DeepSeek Finance Project - Investing.com Scrapers
# -----------------------------------------------------------------------------

import time
import pandas as pd
import re
from io import StringIO
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import selenium_utils

def fetch_investing_source(name, url, chrome_options, days_to_keep=180):
    """
    é€šç”¨ Investing.com å†å²æ•°æ®æŠ“å–
    æ”¯æŒä¸­æ–‡/è‹±æ–‡è¡¨å¤´ï¼Œæ”¯æŒé¡µé¢æ»šåŠ¨æ‡’åŠ è½½
    """
    max_retries = 5
    last_error = None
    
    for attempt in range(1, max_retries + 1):
        print(f"ğŸŒ [{name}] ç¬¬ {attempt}/{max_retries} æ¬¡å°è¯• (Selenium - Investingä¸“çº¿)...")
        driver = None
        try:
            driver = webdriver.Chrome(options=chrome_options)
            driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
                "source": """Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"""
            })

            driver.set_page_load_timeout(60)
            driver.set_script_timeout(60)
            driver.get(url)
            
            # [å…³é”®] æ»šåŠ¨é¡µé¢ä»¥è§¦å‘æ‡’åŠ è½½ (ç‰¹åˆ«æ˜¯å¯¹äº ICE/BDI/SKEW)
            try:
                driver.execute_script("window.scrollBy(0, 500);")
                time.sleep(2)
                WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.TAG_NAME, "table")))
            except:
                pass
            
            html = driver.page_source
            dfs = pd.read_html(StringIO(html))
            
            if not dfs:
                raise ValueError("é¡µé¢è§£æä¸ºç©ºï¼Œæœªæ‰¾åˆ°è¡¨æ ¼æ•°æ®")

            target_df = None
            
            # å¢å¼ºè¡¨å¤´åŒ¹é…é€»è¾‘
            for df in dfs:
                cols = [str(c).replace(" ", "").replace("\n", "").strip() for c in df.columns]
                # Check for Chinese Headers
                if all(k in cols for k in ['æ—¥æœŸ', 'æ”¶ç›˜']):
                    target_df = df
                    break
                # Check for English Headers
                if all(k in cols for k in ['Date', 'Price']):
                    target_df = df
                    break
            
            if target_df is None:
                # Fallback: check only date/close partials
                for df in dfs:
                    cols = [str(c).strip() for c in df.columns]
                    if ('æ—¥æœŸ' in cols and 'æ”¶ç›˜' in cols) or ('Date' in cols and 'Price' in cols):
                        target_df = df
                        break

            if target_df is None:
                    raise ValueError(f"æœªæ‰¾åˆ°ç¬¦åˆ Investing æ ¼å¼çš„è¡¨æ ¼")

            df = target_df.copy()
            
            # Standardize Column Names
            rename_map = {
                'æ—¥æœŸ': 'æ—¥æœŸ', 'æ”¶ç›˜': 'close', 'å¼€ç›˜': 'open',
                'é«˜': 'high', 'ä½': 'low', 'äº¤æ˜“é‡': 'volume', 'æ¶¨è·Œå¹…': 'change_pct',
                'Date': 'æ—¥æœŸ', 'Price': 'close', 'Open': 'open',
                'High': 'high', 'Low': 'low', 'Vol.': 'volume', 'Change %': 'change_pct'
            }
            
            actual_cols = {}
            for col in df.columns:
                clean_col = str(col).strip()
                if clean_col in rename_map:
                    actual_cols[col] = rename_map[clean_col]
            
            df = df.rename(columns=actual_cols)
            
            df['_std_date'] = df['æ—¥æœŸ'].apply(selenium_utils.clean_investing_date)
            df = df.dropna(subset=['_std_date'])
            df['_std_date'] = pd.to_datetime(df['_std_date'])
            
            # [ä¿®æ”¹] æ•°æ®å›é€€æœºåˆ¶ï¼šå¦‚æœæŒ‰æ—¥æœŸè¿‡æ»¤åä¸ºç©ºï¼Œä½†åŸå§‹æ•°æ®ä¸ä¸ºç©ºï¼ˆè¯´æ˜æ•°æ®è¿‡æ—§ï¼‰ï¼Œåˆ™å¼ºåˆ¶è¿”å›æœ€æ–° N æ¡
            df = df.sort_values(by='_std_date', ascending=False)
            
            cutoff_date = pd.Timestamp.now() - pd.Timedelta(days=days_to_keep)
            filtered_df = df[df['_std_date'] >= cutoff_date]
            
            if filtered_df.empty and not df.empty:
                latest_date_str = df.iloc[0]['_std_date'].strftime('%Y-%m-%d')
                print(f"âš ï¸ [{name}] æ•°æ®è¿‡æ—§ (Latest: {latest_date_str})ï¼Œè¶…å‡º {days_to_keep} å¤©èŒƒå›´ã€‚è‡ªåŠ¨å›é€€: è¿”å›æœ€æ–° 5 æ¡ã€‚")
                df = df.head(5)
            else:
                df = filtered_df
            
            df['_std_date'] = df['_std_date'].dt.strftime('%Y-%m-%d')
            
            if 'volume' in df.columns:
                df['volume'] = df['volume'].apply(selenium_utils.parse_volume)
            for col in ['close', 'open', 'high', 'low']:
                if col in df.columns:
                    df[col] = df[col].astype(str).str.replace(',', '', regex=False)
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            if 'change_pct' in df.columns:
                df['change_pct'] = df['change_pct'].apply(selenium_utils.parse_percentage)

            keep_cols = ['_std_date'] + list(set(rename_map.values()))
            final_cols = [c for c in keep_cols if c in df.columns]
            
            df = df[final_cols]
            df.rename(columns={'_std_date': 'æ—¥æœŸ'}, inplace=True)
            
            records = df.to_dict('records')
            print(f"âœ… [{name}] æŠ“å–æˆåŠŸ! è·å¾— {len(records)} æ¡è®°å½•")
            return name, records, None 

        except Exception as e:
            last_error = str(e)
            print(f"âŒ [{name}] å¤±è´¥: {str(e)[:100]}")
            if attempt < max_retries:
                time.sleep(2)
        finally:
            if driver:
                try:
                    driver.quit()
                except:
                    pass
    return name, [], last_error

def fetch_investing_economic_calendar(name, url, chrome_options, days_to_keep=150):
    """
    æŠ“å– Investing.com è´¢ç»æ—¥å†æ•°æ®
    """
    max_retries = 3
    last_error = None
    
    for attempt in range(1, max_retries + 1):
        print(f"ğŸŒ [{name}] ç¬¬ {attempt}/{max_retries} æ¬¡å°è¯• (Selenium - Calendar)...")
        driver = None
        try:
            driver = webdriver.Chrome(options=chrome_options)
            driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
                "source": """Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"""
            })
            driver.set_page_load_timeout(45)
            driver.get(url)
            
            try:
                WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.TAG_NAME, "table")))
            except:
                pass
            
            html = driver.page_source
            dfs = pd.read_html(StringIO(html))
            
            target_df = None
            for df in dfs:
                cols = [str(c).lower() for c in df.columns]
                if any("release date" in c for c in cols) and any("actual" in c for c in cols):
                    target_df = df
                    break
            
            if target_df is None:
                raise ValueError("æœªæ‰¾åˆ°è´¢ç»æ—¥å†æ•°æ®è¡¨æ ¼")
            
            df = target_df.copy()
            new_cols = {}
            for c in df.columns:
                c_str = str(c).strip()
                if "Release Date" in c_str: new_cols[c] = "Release Date"
                elif "Actual" in c_str: new_cols[c] = "Actual"
                elif "Forecast" in c_str: new_cols[c] = "Forecast"
                elif "Previous" in c_str: new_cols[c] = "Previous"
            
            df.rename(columns=new_cols, inplace=True)
            
            def parse_calendar_date(x):
                try:
                    x = re.sub(r'\(.*?\)', '', str(x)).strip()
                    return pd.to_datetime(x, format='%b %d, %Y')
                except:
                    return pd.NaT

            if 'Release Date' not in df.columns:
                raise ValueError("åˆ—åè¯†åˆ«å¤±è´¥")

            df['std_date'] = df['Release Date'].apply(parse_calendar_date)
            df = df.dropna(subset=['std_date'])
            
            cutoff_date = pd.Timestamp.now() - pd.Timedelta(days=days_to_keep)
            df = df[df['std_date'] >= cutoff_date]
            
            records = []
            for _, row in df.iterrows():
                records.append({
                    "æ—¥æœŸ": row['std_date'].strftime('%Y-%m-%d'),
                    "å®é™…å€¼": str(row.get('Actual', '')).strip(),
                    "é¢„æµ‹å€¼": str(row.get('Forecast', '')).strip(),
                    "å‰å€¼": str(row.get('Previous', '')).strip()
                })
            
            print(f"âœ… [{name}] æŠ“å–æˆåŠŸ! è·å¾— {len(records)} æ¡è®°å½• (è¿‘ {days_to_keep} å¤©)")
            return name, records, None

        except Exception as e:
            last_error = str(e)
            print(f"âŒ [{name}] å¤±è´¥: {str(e)[:100]}")
            if attempt < max_retries:
                time.sleep(2)
        finally:
            if driver:
                try:
                    driver.quit()
                except:
                    pass
    return name, [], last_error

def fetch_fed_rate_monitor(name, url, chrome_options):
    """
    æŠ“å– Investing.com Fed Rate Monitor Tool
    """
    max_retries = 3
    last_error = None
    
    for attempt in range(1, max_retries + 1):
        print(f"ğŸŒ [{name}] ç¬¬ {attempt}/{max_retries} æ¬¡å°è¯• (Selenium - FedRate)...")
        driver = None
        try:
            driver = webdriver.Chrome(options=chrome_options)
            driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
                "source": """Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"""
            })
            driver.set_page_load_timeout(45)
            driver.get(url)
            
            try:
                WebDriverWait(driver, 20).until(
                    EC.text_to_be_present_in_element((By.TAG_NAME, "body"), "Fed Interest Rate Decision")
                )
            except:
                pass

            body_text = driver.find_element(By.TAG_NAME, "body").text
            normalized_text = re.sub(r'\s+', ' ', body_text).strip()
            
            # è§£ææ—¥æœŸ
            meeting_date = "Unknown"
            date_match = re.search(r"Meeting Time:\s*([A-Za-z]{3}\s\d{1,2},\s\d{4})", normalized_text)
            if not date_match:
                date_match = re.search(r"Fed Interest Rate Decision\s*([A-Za-z]{3}\s\d{1,2},\s\d{4})", normalized_text)
            if date_match:
                meeting_date = date_match.group(1).strip()
            
            # è§£ææ¦‚ç‡è¡¨
            table_pattern = r"(\d+\.\d+\s*-\s*\d+\.\d+)\s+([\d\.]+%)\s+([\d\.]+%)\s+([\d\.]+%)(?:\s|$)"
            matches = re.findall(table_pattern, normalized_text)
            
            if not matches:
                raise ValueError("æœªåŒ¹é…åˆ°åˆ©ç‡æ¦‚ç‡è¡¨æ•°æ®")

            records = []
            fetch_date = pd.Timestamp.now().strftime('%Y-%m-%d')
            
            for m in matches:
                records.append({
                    "æŠ“å–æ—¥æœŸ": fetch_date,
                    "ä¼šè®®æ—¥æœŸ": meeting_date,
                    "ç›®æ ‡åˆ©ç‡åŒºé—´": m[0],
                    "å½“å‰æ¦‚ç‡": m[1],
                    "å‰ä¸€æ—¥æ¦‚ç‡": m[2],
                    "å‰ä¸€å‘¨æ¦‚ç‡": m[3]
                })
            
            print(f"âœ… [{name}] æŠ“å–æˆåŠŸ! ä¼šè®®: {meeting_date}, è·å¾— {len(records)} ä¸ªåŒºé—´æ•°æ®")
            return name, records, None

        except Exception as e:
            last_error = str(e)
            print(f"âŒ [{name}] å¤±è´¥: {str(e)[:100]}")
            if attempt < max_retries:
                time.sleep(2)
        finally:
            if driver:
                try:
                    driver.quit()
                except:
                    pass
    return name, [], last_error